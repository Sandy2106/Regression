{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "JdO9z4XbfDlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "- Simple Linear Regression is a method used to model the relationship between a dependent variable Y and a single independent variable X using the equation:\n",
        "  - Y=mX+c\n",
        "- Here, m is the slope and c is the intercept.\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "- Linearity: The relationship between X and Y is linear.\n",
        "- Independence: Observations are independent of each other.\n",
        "- Homoscedasticity: Constant variance of residuals across all levels of X.\n",
        "- Normality of Residuals: Residuals are normally distributed.\n",
        "- No significant outliers.\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "- m is the slope of the line. It shows the amount by which Y changes for each one-unit increase in X.\n",
        "\n",
        "4. What does the intercept c represent in the equation Y = mX + c?\n",
        "- c is the value of Y when X = 0. It represents the starting point of the line on the Y-axis.\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "- m= nâˆ‘XYâˆ’âˆ‘Xâˆ‘Y/nâˆ‘X\n",
        "  - Where n is the number of observations.\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "- To minimize the sum of the squared differences between actual and predicted values of Y (i.e., residuals).\n",
        "\n",
        "7. How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?\n",
        "- RÂ² represents the proportion of the variance in Y explained by X.\n",
        "\n",
        "- RÂ² = 1 â†’ perfect fit\n",
        "\n",
        "- RÂ² = 0 â†’ no linear relationship\n",
        "\n",
        "8. What is Multiple Linear Regression?\n",
        "It is an extension of Simple Linear Regression involving two or more independent variables:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +â‹¯+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "â€‹\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "- Simple: One independent variable\n",
        "\n",
        "- Multiple: Two or more independent variables\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "- Linearity\n",
        "\n",
        "- Independence\n",
        "\n",
        "- Homoscedasticity\n",
        "\n",
        "- Normality of residuals\n",
        "\n",
        "- No multicollinearity between predictors\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "- Heteroscedasticity occurs when residuals have unequal variance across levels of an independent variable. It makes standard errors unreliable, affecting confidence intervals and hypothesis tests.\n",
        "\n",
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "- Remove or combine correlated predictors\n",
        "\n",
        "- Use Principal Component Analysis (PCA)\n",
        "\n",
        "- Apply regularization (e.g., Ridge, Lasso)\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "- One-Hot Encoding\n",
        "\n",
        "- Label Encoding\n",
        "\n",
        "- Ordinal Encoding\n",
        "\n",
        "- Binary Encoding\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "- They help model situations where the effect of one variable on Y depends on the level of another variable (e.g.,\n",
        "ğ‘‹\n",
        "1\n",
        "Ã—\n",
        "ğ‘‹\n",
        "2\n",
        "X\n",
        "1\n",
        "â€‹\n",
        " Ã—X\n",
        "2\n",
        "â€‹\n",
        " ).\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "- Simple: Intercept is the value of Y when X = 0\n",
        "\n",
        "- Multiple: Intercept is Y when all predictors = 0, which may not be meaningful\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "- The slope indicates how much the dependent variable changes with a one-unit increase in the independent variable. Itâ€™s crucial for prediction and interpretation.\n",
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "- It gives the baseline value of the dependent variable when all independent variables are zero.\n",
        "\n",
        "18. What are the limitations of using RÂ² as a sole measure of model performance?\n",
        "- Doesnâ€™t indicate if the model is good\n",
        "\n",
        "- Can be artificially high with many variables\n",
        "\n",
        "- Doesnâ€™t capture overfitting\n",
        "\n",
        "- Not useful for comparing models with different numbers of predictors\n",
        "\n",
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "- It means the coefficient estimate is uncertain and possibly not statistically significant.\n",
        "\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "- It appears as a funnel or pattern in residual vs. fitted value plots. Itâ€™s important to fix it because it leads to invalid inference (e.g., biased standard errors).\n",
        "\n",
        "21. What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²?\n",
        "- Some predictors may be irrelevant or overfitting the data. Adjusted RÂ² accounts for the number of predictors, penalizing complexity.\n",
        "\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "- To ensure equal weighting, improve model convergence, and interpret coefficients consistently, especially when regularization is used.\n",
        "\n",
        "23. What is polynomial regression?\n",
        "- A form of regression where the relationship between the independent and dependent variable is modeled as a polynomial equation.\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "- Linear: Models a straight-line relationship\n",
        "\n",
        "- Polynomial: Models curved relationships using powers of the independent variable\n",
        "\n",
        "25. When is polynomial regression used?\n",
        "- When the data shows a nonlinear pattern that a straight line cannot capture.\n",
        "\n",
        "26. What is the general equation for polynomial regression?\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘\n",
        "0\n",
        "+\n",
        "ğ‘\n",
        "1\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ‘\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "Y=b\n",
        "0\n",
        "â€‹\n",
        " +b\n",
        "1\n",
        "â€‹\n",
        " X+b\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        " +â‹¯+b\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        "- Yes, it can include polynomial terms for each variable and their interactions.\n",
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        "- Risk of overfitting\n",
        "\n",
        "- Poor extrapolation\n",
        "\n",
        "- Sensitive to outliers\n",
        "\n",
        "- Complexity increases rapidly with degree\n",
        "\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "- Cross-validation\n",
        "\n",
        "- Adjusted RÂ²\n",
        "\n",
        "- AIC/BIC\n",
        "\n",
        "- Residual analysis\n",
        "\n",
        "- Visualization\n",
        "\n",
        "30. Why is visualization important in polynomial regression?\n",
        "- It helps you assess how well the model fits the data and detect overfitting or underfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZyyDJJZafFCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?"
      ],
      "metadata": {
        "id": "6EGz-PDijm2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Example: 2nd-degree polynomial regression\n",
        "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "model.fit(X, y)\n",
        "predictions = model.predict(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "88-bncgUjqoN",
        "outputId": "1fe2788d-57e2-4ce3-bd10-d419a1591817"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a698faa20e2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Example: 2nd-degree polynomial regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    }
  ]
}